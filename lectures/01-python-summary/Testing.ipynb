{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You will make mistakes when programming! Everyone does. The trick is in spotting the mistakes early and efficiently (after release/publication is normally undesirable).\n",
    "\n",
    "Best tool available: Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why should we test?\n",
    "\n",
    "* To check correctness of software.\n",
    "* To ensure that future changes do not break functionality.\n",
    "* To check if the software runs succesfully in a different environment (newer Python version, upgraded libraries, different operating system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to write unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Identify a *unit* in your program that should have a well defined behavior given a certain input. A unit can be a:\n",
    "   - function\n",
    "   - module\n",
    "   - entire program\n",
    " 1. Write a test function that calls this input and checks that the output/behavior is as expected\n",
    " 1. The more the better! Preferably on several levels (function/module/program)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to write unit tests in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a test framework like [py.test](http://docs.pytest.org/en/latest/). Several other frameworks exist as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pip install pytest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a file `test_<unit_or_module name>.py`, preferably in a folder called `tests`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Import the code to be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Add a function `def test_<test_name>():`, and have it check for the correct behavior given a certain input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Say you have a function `absolute_value` in a file that needs testing:\n",
    "```python\n",
    "# math_tools.py \n",
    "def absolute_value(x):\n",
    "    if x < 0:\n",
    "        return x\n",
    "    else:\n",
    "        return -x\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Create a associated test file `test_math_tools.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```python\n",
    "# test_math_tools.py\n",
    "\n",
    "# Import the function to be tested\n",
    "from math_tools import absolute_value    \n",
    "\n",
    "# py.test will automatically run functions starting with test_ \n",
    "def test_verify_absolute_func():         \n",
    "    # Add some tests here...\n",
    "    assert absolute_value(-3) == 3       \n",
    "    assert absolute_value(5)  == 5       \n",
    "    assert absolute_value(0)  == 0    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `py.test` in the folder containing your project. The tools will look for anything that looks like a test (e.g. `test_*()` functions in `test_*.py` files) in your project (also subdirectories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1) Save the following code as `math_tools.py`\n",
    "\n",
    "```python\n",
    "# math_tools.py \n",
    "def is_even(x):\n",
    "    if x%2==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "```\n",
    "\n",
    "2) Create a `test_math_tools.py` file that tests this functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.9.7, pytest-7.1.2, pluggy-1.0.0\r\n",
      "rootdir: /home/vegard/GRA4157/lectures/01-python-summary\r\n",
      "plugins: anyio-3.6.1\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 5 items                                                              \u001b[0m\r\n",
      "\r\n",
      "test_math_tools.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                 [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!py.test test_math_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Utilities to express expected behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `assert` and comparisons operators like `==`, `>` etc. should be able to express most expected behaviors, there are a few utilities that can greatly simplify tests, for instance:\n",
    "\n",
    "\n",
    "* `pytest.approx` to compare floating point numbers:\n",
    "\n",
    "    Instead of \n",
    "    ```python\n",
    "    abs((0.1 + 0.2) - 0.3) < 1e-8  # Note that floating point arithmetic does not need to be exact\n",
    "    ```\n",
    "\n",
    "    you can use: \n",
    "    ```python\n",
    "    0.1 + 0.2 == pytest.approx(0.3)  \n",
    "    ```\n",
    "\n",
    "* `pytest.raises` to test that a Excelption is raised\n",
    "* `pytest.mark.xfail` to mark a test as expected to fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Numpy tests (more details next week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 7 decimals\n\nMismatched elements: 81 / 100 (81%)\nMax absolute difference: 9.93961809e-07\nMax relative difference: inf\n x: array([[8.6465986e-07, 1.4596450e-07, 1.4953236e-07, 5.2061775e-07,\n        6.6411118e-07, 8.0412424e-07, 8.7157418e-07, 9.3919364e-07,\n        1.4359560e-07, 8.8794707e-08],...\n y: array(0.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m small_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_almost_equal(small_noise, \u001b[38;5;241m0.0\u001b[39m, decimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# OK\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_almost_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/testing/_private/utils.py:844\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    840\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    841\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    842\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    843\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 844\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 7 decimals\n\nMismatched elements: 81 / 100 (81%)\nMax absolute difference: 9.93961809e-07\nMax relative difference: inf\n x: array([[8.6465986e-07, 1.4596450e-07, 1.4953236e-07, 5.2061775e-07,\n        6.6411118e-07, 8.0412424e-07, 8.7157418e-07, 9.3919364e-07,\n        1.4359560e-07, 8.8794707e-08],...\n y: array(0.)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "small_noise = 1e-6 * np.random.rand(10, 10)\n",
    "np.testing.assert_almost_equal(small_noise, 0.0, decimal=5)  # OK\n",
    "np.testing.assert_almost_equal(small_noise, 0.0, decimal=7)  # Will likely fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parametrising tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have many different cases to cover, it is more elegant to use a paramerised test rather than many assert statements:\n",
    "\n",
    "```python\n",
    "@pytest.mark.parametrize(\"x, expected_value\", [(-100,100) (-1,1), (0,0), (0.5,0.5) (1,1)])\n",
    "\n",
    "\n",
    "def test_absolute_func(x, expected_value):            \n",
    "    assert absolute_value(x) == expected_value\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## On the importance of good names for tests:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Good testing practices\n",
    "\n",
    "* Add new test while you develop new features.\n",
    "* Make each test an unique stand alone example.\n",
    "* Making tests resource undemanding.\n",
    "* Run test suite before each commit-push.\n",
    "* Make test function names descriptive.\n",
    "* Quick way to learn other peoples code is through test suits."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
