{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "With conda, you can install the required dependencies with:\n",
    "\n",
    "```bash\n",
    "conda install bs4 requests lxml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage of BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the `BeatifulSoup` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the html source file from disk and pass the source the the BeautifulSoup constructor. We choose the \"lxml\" parser for XML documents, which is faster than the defaul parser that comes with BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<body>\n",
      "<h2>An Unordered HTML List</h2>\n",
      "<ul id=\"unordered_list\" style=\"color:#069\">\n",
      "<li>Coffee</li>\n",
      "<li>Tea</li>\n",
      "<li>Milk</li>\n",
      "</ul>\n",
      "<h2>An Ordered HTML List</h2>\n",
      "<ol id=\"ordered_list\" style=\"color:#069\">\n",
      "<li>Coffee</li>\n",
      "<li>Tea</li>\n",
      "<li>Milk</li>\n",
      "</ol>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src = open(\"list.html\")\n",
    "document = BeautifulSoup(src, 'lxml')\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding tags by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document now contains the full html document. We can find the first occuring tag with a specific name with the `find` function. Let's find the first un-ordered list tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulist = document.find(\"ul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result contains all tags contained in the matched tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul id=\"unordered_list\" style=\"color:#069\">\n",
       "<li>Coffee</li>\n",
       "<li>Tea</li>\n",
       "<li>Milk</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_all` function returns **all** tags that match the given tag name. We can use it to get a list of all list items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>Coffee</li>, <li>Tea</li>, <li>Milk</li>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = ulist.find_all(\"li\")\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can loop over all items and extract their contant with the `get_text` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coffee\n",
      "Tea\n",
      "Milk\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `find_all` is **recursive** by default. This means that we could call it the on the full `document` to get the items\n",
    "of both the ordered and un-ordered lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.find_all(\"li\", recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding tags by attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the easiest way to find a tag is by its attribute name. In our examples, both lists have an `id` attribute that uniquely identifies the tables. We can also use the `find*` methods to search for attributes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul id=\"unordered_list\" style=\"color:#069\">\n",
       "<li>Coffee</li>\n",
       "<li>Tea</li>\n",
       "<li>Milk</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.find(attrs={\"id\":\"unordered_list\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ul` tag also contains a `style` attribute. Any bs4 tag behaves like a dictionary with attribute names as keys and attribute values as values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'unordered_list', 'style': 'color:#069'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulist.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'color:#069'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulist[\"style\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a table from Wikipedia\n",
    "\n",
    "We aim to get a list of countries sorted by their population size:\n",
    "https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we load the html source directly from a website using the requests module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(\"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web server returns a status code to indicate if the request was (un-)succesfully.\n",
    "We use that status-code to check if the page was succesfully loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert result.status_code==200  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the html source and initiated BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = result.content\n",
    "document = BeautifulSoup(src, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by looking at the document, we can see that we are interested in first table. So we use `find`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = document.find(\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not familiar with html table, read this example first: https://www.w3schools.com/html/tryit.asp?filename=tryhtml_table_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it is a good idea to programatically check that the table contains the correct header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert table.find(\"th\").get_text() == \"Rank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_all(\"tr\")  # Note: this works because find_all is resursive by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, China, Asia\n",
      "2, India, Asia\n",
      "3, United States, North America\n",
      "4, Indonesia, Asia[b]\n",
      "5, Pakistan, Asia\n",
      "6, Nigeria, Africa\n",
      "7, Brazil, South America\n",
      "8, Bangladesh, Asia\n",
      "9, Russia, Europe[c]\n",
      "10, Mexico, North America\n",
      "11, Japan, Asia\n",
      "12, Philippines, Asia\n",
      "13, Ethiopia, Africa\n",
      "14, Egypt, Africa[b]\n",
      "15, Vietnam, Asia\n",
      "16, DR Congo, Africa\n",
      "17, Iran, Asia\n",
      "18, Turkey, Asia[b]\n",
      "19, Germany, Europe\n",
      "20, France, Europe\n",
      "21, United Kingdom, Europe\n",
      "22, Thailand, Asia\n",
      "23, Tanzania, Africa\n",
      "24, South Africa, Africa\n",
      "25, Italy, Europe\n",
      "26, Myanmar, Asia\n",
      "27, South Korea, Asia\n",
      "28, Colombia, South America\n",
      "29, Kenya, Africa\n",
      "30, Spain, Europe\n",
      "31, Argentina, South America\n",
      "32, Algeria, Africa\n",
      "33, Sudan, Africa\n",
      "34, Uganda, Africa\n",
      "35, Iraq, Asia\n",
      "36, Ukraine, Europe\n",
      "37, Canada, North America\n",
      "38, Poland, Europe\n",
      "39, Morocco, Africa\n",
      "40, Uzbekistan, Asia\n",
      "41, Saudi Arabia, Asia\n",
      "42, Peru, South America\n",
      "43, Angola, Africa\n",
      "44, Afghanistan, Asia\n",
      "45, Malaysia, Asia\n",
      "46, Mozambique, Africa\n",
      "47, Yemen, Asia\n",
      "48, Ghana, Africa\n",
      "49, Ivory Coast, Africa\n",
      "50, Venezuela, South America\n",
      "51, Nepal, Asia\n",
      "52, Madagascar, Africa\n",
      "53, Australia, Oceania\n",
      "54, North Korea, Asia\n",
      "55, Cameroon, Africa\n",
      "56, Niger, Africa\n",
      "–, Taiwan, Asia\n",
      "57, Sri Lanka, Asia\n",
      "58, Burkina Faso, Africa\n",
      "59, Malawi, Africa\n",
      "60, Mali, Africa\n",
      "61, Chile, South America\n",
      "62, Kazakhstan, Asia[b]\n",
      "63, Romania, Europe\n",
      "64, Zambia, Africa\n",
      "65, Syria, Asia\n",
      "66, Ecuador, South America\n",
      "67, Netherlands, Europe\n",
      "68, Senegal, Africa\n",
      "69, Guatemala, North America\n",
      "70, Chad, Africa\n",
      "71, Somalia, Africa\n",
      "72, Cambodia, Asia\n",
      "73, Zimbabwe, Africa\n",
      "74, South Sudan, Africa\n",
      "75, Rwanda, Africa\n",
      "76, Guinea, Africa\n",
      "77, Burundi, Africa\n",
      "78, Benin, Africa\n",
      "79, Tunisia, Africa\n",
      "80, Bolivia, South America\n",
      "81, Haiti, North America\n",
      "82, Belgium, Europe\n",
      "83, Jordan, Asia\n",
      "84, Cuba, North America\n",
      "85, Dominican Republic, North America\n",
      "86, Czech Republic, Europe\n",
      "87, Sweden, Europe\n",
      "88, Greece, Europe\n",
      "89, Portugal, Europe\n",
      "90, Azerbaijan, Asia[b]\n",
      "91, Hungary, Europe\n",
      "92, Israel, Asia\n",
      "93, Honduras, North America\n",
      "94, Tajikistan, Asia\n",
      "95, United Arab Emirates, Asia\n",
      "96, Belarus, Europe\n",
      "97, Papua New Guinea, Oceania\n",
      "98, Austria, Europe\n",
      "99, Switzerland, Europe\n",
      "100, Sierra Leone, Africa\n",
      "101, Togo, Africa\n",
      "–, Hong Kong(China), Asia\n",
      "102, Paraguay, South America\n",
      "103, Laos, Asia\n",
      "104, Libya, Africa\n",
      "105, El Salvador, North America\n",
      "106, Serbia, Europe\n",
      "107, Lebanon, Asia\n",
      "108, Kyrgyzstan, Asia\n",
      "109, Nicaragua, North America\n",
      "110, Bulgaria, Europe\n",
      "111, Turkmenistan, Asia\n",
      "112, Denmark, Europe\n",
      "113, Congo, Africa\n",
      "114, Central African Republic, Africa\n",
      "115, Finland, Europe\n",
      "116, Singapore, Asia\n",
      "117, Norway, Europe\n",
      "118, Slovakia, Europe\n",
      "119, Palestine, Asia\n",
      "120, Costa Rica, North America\n",
      "121, New Zealand, Oceania\n",
      "122, Ireland, Europe\n",
      "123, Kuwait, Asia\n",
      "124, Liberia, Africa\n",
      "125, Oman, Asia\n",
      "126, Panama, North America\n",
      "127, Mauritania, Africa\n",
      "128, Croatia, Europe\n",
      "129, Georgia, Asia[b]\n",
      "130, Eritrea, Africa\n",
      "131, Uruguay, South America\n",
      "132, Mongolia, Asia\n",
      "133, Bosnia and Herzegovina, Europe\n",
      "–, Puerto Rico(United States), North America\n",
      "134, Armenia, Asia\n",
      "135, Lithuania, Europe\n",
      "136, Albania, Europe\n",
      "137, Qatar, Asia\n",
      "138, Jamaica, North America\n",
      "139, Moldova, Europe\n",
      "140, Namibia, Africa\n",
      "141, Gambia, Africa\n",
      "142, Botswana, Africa\n",
      "143, Gabon, Africa\n",
      "144, Lesotho, Africa\n",
      "145, Slovenia, Europe\n",
      "146, Latvia, Europe\n",
      "147, North Macedonia, Europe\n",
      "–, Kosovo, Europe\n",
      "148, Guinea-Bissau, Africa\n",
      "149, Equatorial Guinea, Africa\n",
      "150, Bahrain, Asia\n",
      "151, Trinidad and Tobago, North America\n",
      "152, Estonia, Europe\n",
      "153, East Timor, Asia\n",
      "154, Mauritius, Africa\n",
      "155, Eswatini, Africa\n",
      "156, Djibouti, Africa\n",
      "157, Cyprus, Asia\n",
      "158, Fiji, Oceania\n",
      "159, Comoros, Africa\n",
      "160, Bhutan, Asia\n",
      "161, Guyana, South America\n",
      "162, Solomon Islands, Oceania\n",
      "–, Macau(China), Asia\n",
      "163, Luxembourg, Europe\n",
      "164, Montenegro, Europe\n",
      "–, Western Sahara, Africa\n",
      "165, Suriname, South America\n",
      "166, Cape Verde, Africa\n",
      "167, Malta, Europe\n",
      "168, Belize, North America\n",
      "169, Brunei, Asia\n",
      "170, Bahamas, North America\n",
      "171, Maldives, Asia\n",
      "–, Northern Cyprus, Asia\n",
      "172, Iceland, Europe\n",
      "–, Transnistria, Europe\n",
      "173, Vanuatu, Oceania\n",
      "174, Barbados, North America\n",
      "–, French Polynesia(France), Oceania\n",
      "–, New Caledonia(France), Oceania\n",
      "–, Abkhazia, Asia\n",
      "175, São Tomé and Príncipe, Africa\n",
      "176, Samoa, Oceania\n",
      "177, Saint Lucia, North America\n",
      "–, Guam(United States), Oceania\n",
      "–, Curaçao(Netherlands), North America\n",
      "–, Artsakh, Asia\n",
      "178, Kiribati, Oceania\n",
      "179, Grenada, North America\n",
      "–, Aruba(Netherlands), North America\n",
      "180, Saint Vincent and the Grenadines, North America\n",
      "–, Jersey(British Crown Dependency), Europe\n",
      "181, Micronesia, Oceania\n",
      "182, Tonga, Oceania\n",
      "183, Antigua and Barbuda, North America\n",
      "184, Seychelles, Africa\n",
      "–, U.S. Virgin Islands(United States), North America\n",
      "–, Isle of Man(British Crown Dependency), Europe\n",
      "185, Andorra, Europe\n",
      "186, Dominica, North America\n",
      "–, Cayman Islands(United Kingdom), North America\n",
      "–, Bermuda(United Kingdom), North America\n",
      "–, Guernsey(British Crown Dependency), Europe\n",
      "–, Greenland(Denmark), North America\n",
      "187, Marshall Islands, Oceania\n",
      "188, Saint Kitts and Nevis, North America\n",
      "–, Faroe Islands(Denmark), Europe\n",
      "–, South Ossetia, Asia\n",
      "–, American Samoa(United States), Oceania\n",
      "–, Northern Mariana Islands(United States), Oceania\n",
      "–, Turks and Caicos Islands(United Kingdom), North America\n",
      "–, Sint Maarten(Netherlands), North America\n",
      "189, Liechtenstein, Europe\n",
      "190, Monaco, Europe\n",
      "–, Gibraltar(United Kingdom), Europe\n",
      "191, San Marino, Europe\n",
      "–, Saint Martin(France), North America\n",
      "–, Åland(Finland), Europe\n",
      "–, British Virgin Islands(United Kingdom), North America\n",
      "192, Palau, Oceania\n",
      "–, Cook Islands(New Zealand), Oceania\n",
      "–, Anguilla(United Kingdom), North America\n",
      "193, Nauru, Oceania\n",
      "–, Wallis and Futuna(France), Oceania\n",
      "194, Tuvalu, Oceania\n",
      "–, Saint Barthélemy(France), North America\n",
      "–, Saint Helena, Ascension and Tristan da Cunha(United Kingdom), Africa\n",
      "–, Saint Pierre and Miquelon(France), North America\n",
      "–, Montserrat(United Kingdom), North America\n",
      "–, Falkland Islands(United Kingdom), South America\n",
      "–, Christmas Island(Australia), Oceania\n",
      "–, Norfolk Island(Australia), Oceania\n",
      "–, Niue(New Zealand), Oceania\n",
      "–, Tokelau(New Zealand), Oceania\n",
      "195, Vatican City, Europe\n",
      "–, Cocos (Keeling) Islands(Australia), Oceania\n"
     ]
    }
   ],
   "source": [
    "for row in rows[2:-1]:\n",
    "    cells = row.find_all([\"td\", \"th\"])\n",
    "    \n",
    "    cells_text = [cell.get_text(strip=True) for cell in cells]\n",
    "    (rank, country, region, population, percentage, updated_at, source, comment) = cells_text  \n",
    "    print(f'{rank}, {country}, {region}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: Beautiful Soup does not execute Javascript. This means that you the code in the Google Chrome inspector might look different to the original source code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another example of downloading a Wikipedia table \n",
    "\n",
    "Let's consider another table in a Wikipedia page. This page has a lot more tables, so one challenge will be to pick the right table\n",
    "\n",
    "https://en.wikipedia.org/wiki/Tiger_Woods\n",
    "\n",
    "\n",
    "We are interested in extracting these two tables:\n",
    "\n",
    "![Target Wikipedia tables](pictures/wiki_tables.png)\n",
    "\n",
    "**Exercise**: \n",
    "\n",
    "1) Identify the id=\"The_Players_Championship\", by using title = document.find(id=\"The_Players_Championship\")\n",
    "\n",
    "2) First find all tables below the id in 1) by title.find_all_next('table').\n",
    "\n",
    "3) Search for headers (th) by table.find('th') for table in tables to identify the \"Tournament\" header. Remember to use get_text(strip=True)\n",
    "\n",
    "4) Save all tables with the header \"Tournament\" into a list tournament_tables. Check the length of the table and reduce it if it is needed.\n",
    "\n",
    "5) Bonus: Print out the information in the two tables of interest in the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by downloading the webpage and instatiating the BeautifulSoup object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(\"https://en.wikipedia.org/wiki/Tiger_Woods\")\n",
    "src = result.content\n",
    "document = BeautifulSoup(src, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page contains a lot of tables without specific attributes that would make it easy to find our table of interest. Further, the same headings of the tables are used for multiple tables, making it difficult to find a table just by its headings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document.find_all(\"table\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we choose another strategy. First, we extract the tag that defines the header just before our tables of interest. That header tag has a unique identifier attribute `id=\"The_Players_Championship\"`. Then we use the `find_all_next` function in BeautifulSoup to extract all following table tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = document.find(id=\"The_Players_Championship\")\n",
    "tables = title.find_all_next(\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our tables of interest are the first two tables with the \"Tournament\" heading. We write a small helper function (a generator https://wiki.python.org/moin/Generators) that returns a table with a given heading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_table_with_heading(tables, heading):\n",
    "    for table in tables:\n",
    "        if table.find(\"th\").get_text(strip=True) == heading:\n",
    "            yield table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can extract the table rows and columns as usual. We only extract the first two tables, as these are the only ones we were interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tournament', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009']\n",
      "['The Players Championship', 'T31', 'T35', 'T10', '2', '1', 'T14', 'T11', 'T16', 'T53', 'T22', 'T37', '', '8']\n",
      "['Tournament', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
      "['The Players Championship', 'WD', 'WD', 'T40', '1', '', 'T69', '', '', 'T11', 'T30']\n"
     ]
    }
   ],
   "source": [
    "tournament_tables = list(find_table_with_heading(tables, \"Tournament\"))\n",
    "\n",
    "for table in tournament_tables[:2]:\n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cells= row.find_all([\"th\", \"td\"])\n",
    "        print([cell.get_text(strip=\"True\") for cell in cells])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
