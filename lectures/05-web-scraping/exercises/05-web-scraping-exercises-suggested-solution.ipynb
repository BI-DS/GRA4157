{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Scrape NASDAQ Top Gainers\n",
    "Steps:\n",
    "1. **Initial Scrape:** Scrape the NASDAQ Top Gainers Table (https://www.nasdaq.com/market-activity/stocks/screener?exchange=nasdaq&status=top-gainers).\n",
    "1. **Initial Scrape2:** If you get a timeout from NASDAQ try Yahoo Finance (https://finance.yahoo.com/markets/stocks/gainers/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAACvz6Ex45XoUQkTNdDAujGj-X1mDenZIQcqrx6vnpefvlJ9NoDdFaU1W6EO9SzM8m0aA1t7qTMhWSZq2zdbdGfRyC47dQXdu8ZG8IISgSgz6DXTsJe0Jrp3hGEKnAxOCDSjeey7roNKAj5L0UJ68arDOoeeI13BkNR2xMSggz88c)\n",
    "2. **Data Cleanup:** Keep only the 'Symbol', 'Company', and 'Price' columns. With Yahoo data, Symbol and Company name is in the same column. \n",
    "3. **Analysis:** Find the company with the highest stock price.. Hint: With Yahoo you can use the start and count arguments to see all companies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 25 companies, PDD Holdings Inc. has the most expensive share price\n"
     ]
    }
   ],
   "source": [
    "import requests as re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "attrs = {\n",
    "    \"start\": 0,\n",
    "    \"count\": 100\n",
    "}\n",
    "url = \"https://finance.yahoo.com/markets/stocks/gainers/\"\n",
    "results = re.get(url, attrs)\n",
    "src = results.content\n",
    "document = BeautifulSoup(src, \"lxml\")\n",
    "tables = document.find_all(\"table\")    # I verify that this has len(1)\n",
    "table = tables[0]\n",
    "data = {\"Symbol\": [], \"Company\": [], \"Price\": []}\n",
    "rows = table.find_all(\"tr\")\n",
    "for row in rows[1:]:\n",
    "    values = [c.get_text() for c in row.find_all(\"td\")]\n",
    "    symbol_and_name = values[0].split()\n",
    "    symbol = symbol_and_name[0]\n",
    "    company_name = \" \".join(symbol_and_name[1:])\n",
    "    price_chg_pctchg = values[1].split()\n",
    "    price = price_chg_pctchg[0]\n",
    "    data[\"Symbol\"].append(symbol)\n",
    "    data[\"Company\"].append(company_name)\n",
    "    data[\"Price\"].append(float(price))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "sorted_df = df.sort_values(by=\"Price\", ascending=False)\n",
    "top_company = sorted_df.iloc[0]\n",
    "print(f\"Of {len(df)} companies, {top_company.Company} has the most expensive share price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 100 companies, First Solar, Inc. has the most expensive share price\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "url = \"https://finance.yahoo.com/markets/stocks/gainers/?start=0&count=100\"\n",
    "response = session.get(url)\n",
    "tables = response.html.find('table')\n",
    "table = tables[0]\n",
    "rows = table.find('tr')\n",
    "data = {\"Symbol\": [], \"Company\": [], \"Price\": []}\n",
    "for row in rows[1:]:\n",
    "    values = [c.text for c in row.find(\"td\")]\n",
    "    symbol_and_name = values[0].split()\n",
    "    symbol = symbol_and_name[0]\n",
    "    company_name = \" \".join(symbol_and_name[1:])\n",
    "    price_chg_pctchg = values[1].split()\n",
    "    price = price_chg_pctchg[0]\n",
    "    data[\"Symbol\"].append(symbol)\n",
    "    data[\"Company\"].append(company_name)\n",
    "    data[\"Price\"].append(float(price))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "sorted_df = df.sort_values(by=\"Price\", ascending=False)\n",
    "top_company = sorted_df.iloc[0]\n",
    "print(f\"Of {len(df)} companies, {top_company.Company} has the most expensive share price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Scrape Top 250 Movies by Gross income\n",
    "Steps:\n",
    "1. **Initial Scrape:** Scrape BoxOfficeMojo's list of top 250 movies (https://www.boxofficemojo.com/chart/top_lifetime_gross/).\n",
    "2. **Data Cleanup:** Keep only relevant columns such as 'Rank', 'Title', \"Lifetime gross\", and 'Year'.\n",
    "3. **Analysis:** Find the best decade in terms of \"Lifetime gross\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020's had the highest average Gross income\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.boxofficemojo.com/chart/top_lifetime_gross/\"\n",
    "results = re.get(url)\n",
    "src = results.content\n",
    "document = BeautifulSoup(src, \"lxml\")\n",
    "tables = document.find_all(\"table\")\n",
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "data = {\"Title\": [], \"Gross\": [], \"Year\": []}\n",
    "for row in rows[1:]:\n",
    "    elements = [e.get_text() for e in row.find_all(\"td\")]\n",
    "    data[\"Title\"].append(elements[1])\n",
    "    income = elements[2]\n",
    "    income = float(income.replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "    data[\"Gross\"].append(income)\n",
    "    data[\"Year\"].append(int(elements[3]))\n",
    "\n",
    "df = pd.DataFrame(data, index=pd.Index(range(1, len(data[\"Title\"])+1), name=\"Rank\"))\n",
    "decades = [1970 + 10*i for i in range(6)]\n",
    "average_gross = {}\n",
    "max_decade = 0\n",
    "for decade in decades:\n",
    "    decade_df = df[(df[\"Year\"] > decade)*(df[\"Year\"] < decade + 10)]\n",
    "    average_gross[decade] = decade_df[\"Gross\"].mean()\n",
    "    if average_gross[decade] > max_decade:\n",
    "        max_decade = decade\n",
    "\n",
    "print(f\"The {decade}'s had the highest average Gross income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Scrape Wikipedia's List of Best-selling Music Artists\n",
    "Steps:\n",
    "1. **Initial Scrape:** Scrape Wikipedia's table of best-selling music artists (https://en.wikipedia.org/wiki/List_of_best-selling_music_artists).\n",
    "2. **Data Cleanup:** Retain only 'Artist', 'Country/Market', and 'Certified Sales'.\n",
    "3. **Analysis:** Find the artist with the highest certified sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rihanna has the highest certified sales\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_best-selling_music_artists\"\n",
    "results = re.get(url)\n",
    "src = results.content\n",
    "document = BeautifulSoup(src, \"lxml\")\n",
    "tables = document.find_all(\"table\")\n",
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "data = {\"Name\": [], \"Country\": [], \"Certified sales\": []}\n",
    "for row in rows[1:]:\n",
    "    values = row.get_text().split(\"\\n\")\n",
    "    name = values[1]\n",
    "    country = values[3]\n",
    "    sales = float(values[12].strip(\" million\"))\n",
    "    data[\"Name\"].append(name)\n",
    "    data[\"Country\"].append(country)\n",
    "    data[\"Certified sales\"].append(sales)\n",
    "\n",
    "df = pd.DataFrame(data, index=pd.Index(range(1, len(data[\"Name\"])+1), name=\"Claimed rank\"))\n",
    "df_sorted = df.sort_values(by=\"Certified sales\", ascending=False)\n",
    "print(f\"{df_sorted.iloc[0].Name} has the highest certified sales\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Scrape CoinMarketCap's Top 10 Cryptocurrencies\n",
    "Steps:\n",
    "1. **Initial Scrape:** Scrape CoinMarketCap's table of top cryptocurrencies (https://coinmarketcap.com/).\n",
    "2. **Data Cleanup:** Retain only 'Name', 'Symbol', and 'Market Cap'.\n",
    "3. **Analysis:** Identify the cryptocurrency with the highest market cap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin has the higest market cap\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://coinmarketcap.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "height = driver.execute_script(\"return window.innerHeight;\")\n",
    "for _ in range(12):\n",
    "    driver.execute_script(f\"window.scrollBy(0, {height});\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "html_content = driver.page_source\n",
    "document = BeautifulSoup(html_content, \"lxml\")\n",
    "tables = document.find_all(\"table\")\n",
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "data = {\"Company name\": [], \"Symbol\": [], \"Market cap\": []}\n",
    "for row in rows[1:]:\n",
    "    elements = row.find_all(\"td\")\n",
    "    name_and_symbol = elements[2]\n",
    "    name, symbol = [e.get_text() for e in name_and_symbol.find_all(\"p\")]\n",
    "    market_cap_text = elements[7].get_text()\n",
    "    market_cap = float(market_cap_text.split(\"$\")[2].replace(\",\",\"\"))\n",
    "    data[\"Symbol\"].append(symbol)\n",
    "    data[\"Company name\"].append(name)\n",
    "    data[\"Market cap\"].append(float(market_cap))\n",
    "\n",
    "driver.close()\n",
    "df = pd.DataFrame(data, index=pd.Index(range(1, len(data[\"Company name\"])+1), name=\"Rank\"))\n",
    "print(f\"{df.sort_values(by=\"Market cap\", ascending=False).iloc[0][\"Company name\"]} has the higest market cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    #               Name       Price   1h %   24h %    7d %  \\\n",
      "0          NaN    1         BitcoinBTC  $65,824.83  0.41%   3.45%   3.82%   \n",
      "1          NaN    2        EthereumETH   $2,667.25  0.15%   2.00%   4.52%   \n",
      "2          NaN    3         TetherUSDT       $1.00  0.01%   0.05%   0.03%   \n",
      "3          NaN    4             BNBBNB     $606.94  0.25%   2.11%   6.13%   \n",
      "4          NaN    5          SolanaSOL     $158.29  0.26%   4.80%   4.97%   \n",
      "..         ...  ...                ...         ...    ...     ...     ...   \n",
      "95         NaN   96       SATS1000SATS  $0.0003503  0.04%  12.43%  14.23%   \n",
      "96         NaN   97       PendlePENDLE       $4.49  1.08%   4.62%  26.47%   \n",
      "97         NaN   98    The SandboxSAND      $0.298  0.54%   5.52%   8.67%   \n",
      "98         NaN   99    PayPal USDPYUSD     $0.9997  0.01%   0.02%   0.01%   \n",
      "99         NaN  100  dYdX (Native)DYDX       $1.09  0.53%   5.40%  12.85%   \n",
      "\n",
      "                  Market Cap                           Volume(24h)  \\\n",
      "0    $1.3T$1,300,668,246,199            $39,159,099,729594,697 BTC   \n",
      "1   $321.04B$321,038,164,306          $17,633,766,8456,611,264 ETH   \n",
      "2   $119.39B$119,386,449,523    $70,263,870,21670,254,728,339 USDT   \n",
      "3     $88.57B$88,572,952,611           $2,135,179,0393,517,931 BNB   \n",
      "4     $74.21B$74,209,300,919          $3,266,310,99020,635,532 SOL   \n",
      "..                       ...                                   ...   \n",
      "95      $735.54M$735,543,365  $130,515,211373,555,556,626 1000SATS   \n",
      "96      $726.14M$726,136,601         $143,164,77631,829,980 PENDLE   \n",
      "97       $712.1M$712,104,501           $55,021,341184,605,989 SAND   \n",
      "98      $710.29M$710,287,099           $25,188,42525,189,317 PYUSD   \n",
      "99       $692.1M$692,104,032            $28,383,28026,093,030 DYDX   \n",
      "\n",
      "            Circulating Supply  Last 7 Days  \n",
      "0               19,759,537 BTC          NaN  \n",
      "1              120,363,208 ETH          NaN  \n",
      "2         119,354,306,804 USDT          NaN  \n",
      "3              145,933,219 BNB          NaN  \n",
      "4              468,831,181 SOL          NaN  \n",
      "..                         ...          ...  \n",
      "95  2,100,000,000,000 1000SATS          NaN  \n",
      "96          161,577,809 PENDLE          NaN  \n",
      "97          2,389,232,126 SAND          NaN  \n",
      "98           710,466,006 PYUSD          NaN  \n",
      "99            636,340,523 DYDX          NaN  \n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\58263\\AppData\\Local\\Temp\\ipykernel_14096\\2576101274.py:17: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(html_content)[0]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://coinmarketcap.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "height = driver.execute_script(\"return window.innerHeight;\")\n",
    "for _ in range(12):\n",
    "    driver.execute_script(f\"window.scrollBy(0, {height});\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "html_content = driver.page_source\n",
    "driver.close()\n",
    "df = pd.read_html(html_content)[0]\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
